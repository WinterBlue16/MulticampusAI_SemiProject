# :bookmark: SP01_사용 라이브러리 정리

> 다음 댓글 크롤링에서 활용했던 라이브러리를 정리한 문서이다.



## 1. selenium

가상 브라우저를 이용해 댓글과 같이 로딩에 시간이 걸리는 데이터들을 크롤링할 수 있게 해주는 라이브러리이다.  플랫폼 기사의 댓글을 크롤링하기 위해 사용하였다. 

![img](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fct9bnU%2FbtqSdtqgD1W%2FIdk9pFKNyIUNKu4YoWWO0K%2Fimg.png)

```python
pip install selenium # 설치방법
```

이 라이브러리의 핵심은 웹 브라우저 자동화로, 데이터를 얻는 것은 물론 클릭, 마우스 스크롤, 검색어 입력 등의 활동들을 모두 자동화할 수 있다. 때문에 웹 사이트의 프론트엔드 테스트를 할 때 사용되기도 한다. 

### 1-1. selenium.webdriver

웹 크롤링에 핵심이 되는 모듈이다. 브라우저 별로 드라이버를 다운로드해야 하며, 해당 드라이버는 컴퓨터에서 사용 중인 브라우저 버전과 일치해야 한다. 그렇지 않을 경우 에러가 발생한다. 

### 1-2. selenium.common.exceptions.NoSuchElementException

댓글 더보기 버튼의 class name 'link fold'의 존재 유무를 확인하기 위해 check_exists_by_classname이라는 함수를 만들었고, 예외 처리 시 사용하였다. 원래 지정한 위치에 element가 없을 경우 NoSuchElementException에러가 발생하는데, except를 통해 이 에러가 발생할 경우 함수에서 False 값을 반환하도록 했다. 



## 2. bs4

HTML 문서를 파싱하여 데이터 접근을 용이하게 해 주는 라이브러리이다.  selenium으로 선택한 데이터들을 텍스트 데이터로 크롤링하기 위해 사용하였다. 

```python
pip install bs4 # 설치방법
```



### 2-1. BeautifulSoup

![img](https://funthon.files.wordpress.com/2017/05/bs.png)

해당 라이브러리의 이름은 tag soup+동화 이상한 나라의 앨리스에서 유래했다. 

tag soup란 문법, 구조적으로 잘못된 HTML 웹 문서를 가리킨다. 예전의 HTML 문서는 오류에 유연하게 대응할 수 있기 때문에 웹 개발자들이 엄격하게 규칙을 따르지 않는 경우가 많았다고 한다. 엄격하게 규칙을 지킨 코드가 보기도 편한 법이라고, 그러다 보니 HTML과 텍스트가 엉망으로 뒤섞이고 닫는 태그도 제대로 지켜지지 않았다고. 이런 더러운 구조의 웹 문서를 아무렇게나 뒤섞인 수프와 같다고 해서 tag soup란 이름이 붙었단다. 

beautiful soup(아름다운 수프)은 이런 섞어찌개같은 더러운 수프를 아름답게 변환시켜 준다는 의미에서 지어졌다고 한다. 아래는 이상한 나라의 앨리스에서 나오는 내용이다. 

```
"이걸 다 외워서 무슨 소용이야!"
가짜 거북이가 또 끼어들며 말했어요.
"추가 설명 없인 대체 무슨 소린지 하나도 모르겠구나. 내 생전 이렇게 헷갈리는 시는 또 처음이야."

가짜 거북이는 깊은 한 숨을 몰아쉬더니 이따금씩 흐느낌을 삼키는 목소리로 다음과 같은 노래를 부르기 시작했어요.
"아름다운 수프, 풍만한 녹색,
그릇에서 기다리거라!
누가 이 맛있는 것에 숙이지 않으리?
저녁 수프, 아름다운 수프!
아--르음다운 수---프!
저어녀---엌 수---프!
아름다운, 아름다운 수프
```



※ 참고 자료

[준우의 오류노트](https://desarraigado.tistory.com/14)